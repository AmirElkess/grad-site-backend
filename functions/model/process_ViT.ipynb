{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N95yMqBIitVj"
      },
      "source": [
        "# Using Visual Transformers for emotion recognition\n",
        "Dataset: fer-2013"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Required libraries (working on py3.9)\n",
        "torch\n",
        "torchvision\n",
        "datasets\n",
        "transformers\n",
        "matplotlib\n",
        "pillow\n",
        "sklearn\n",
        "opencv-python\n",
        "imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dcVcvgdqVnF",
        "outputId": "1f215ab5-a803-4ecd-d3b6-509053404681"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\AmirElkess\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "from PIL import Image\n",
        "import io\n",
        "from IPython import display\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jFM7RS2qVnN"
      },
      "source": [
        "## Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b686c8b7aa374fd18072ec20f4b9fa8c",
            "2af4c8b59ba24ceb9dd1a935706ba57c",
            "d0e5b153fee24ba4b334d02463a5d0b4",
            "e455b6c2e80c402eb2e9954944c0e634",
            "570471a4c14f4a2b842ae64a58fb34a1",
            "1441a112ee2a4b8c80b2efeabb5855a9",
            "feca5d721e6e4872a4be81bdbf7c7f37",
            "f592a6fd63ca415ea5157c664fa811f5",
            "2d7c1b735e2341b2918b1261806e46b1",
            "38f6d6fdf10f48b393b36997cfeea627",
            "0322e835b5f1408895c264d57b62931e"
          ]
        },
        "id": "OfsQox-7qVnQ",
        "outputId": "e9282d8a-eeb5-4e8d-c503-ba974425eab7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset fer2013 (C:\\Users\\AmirElkess\\.cache\\huggingface\\datasets\\Jeneral___fer2013\\default\\0.0.0\\0fb00ec122d7d9485e58ee9ef0eec3eb193c0d71aadfc61b61d33a46c2d3a45a)\n",
            "100%|██████████| 2/2 [00:00<00:00, 45.67it/s]\n"
          ]
        }
      ],
      "source": [
        "train, test = datasets.load_dataset(\"Jeneral/fer-2013\", split=[\"train\", \"test\"])\n",
        "splits = train.train_test_split(test_size=0.1)\n",
        "train = splits['train']\n",
        "val = splits['test']\n",
        "del splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "Ubp6X9LIqVnS",
        "outputId": "018b67fe-c914-4d5d-9c2f-ab02f3672c06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1f3d1d7ed00>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_data = train[3][\"img_bytes\"]\n",
        "image = Image.open(io.BytesIO(image_data))\n",
        "# image.show()\n",
        "imshow(image, \"gray\") # images are 48*48 grayscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPjC7B9yqVnT",
        "outputId": "d16aeabd-7d07-4d2f-d0ea-ef019c85d27b"
      },
      "outputs": [],
      "source": [
        "id2label = {id:label for id, label in enumerate(train.features['labels'].names)}\n",
        "label2id = {label:id for id, label in id2label.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myogyfugqVnU"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KTuet-IqVnV",
        "outputId": "a55da95a-e1bd-4f20-dd45-d25c666b08e7"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import ViTFeatureExtractor\n",
        "\n",
        "# if problems happen, make sure to run using python 3.9\n",
        "from torchvision.transforms import (\n",
        "    CenterCrop,\n",
        "    Compose,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomResizedCrop,\n",
        "    Resize,\n",
        "    ToTensor,\n",
        ")\n",
        "\n",
        "from torchvision.transforms import Normalize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyAxuW-CqVnW",
        "outputId": "9c658ea6-6ebe-4002-c75e-73dfafa0f726"
      },
      "outputs": [],
      "source": [
        "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MyOo_YwoqVnW"
      },
      "outputs": [],
      "source": [
        "normalize = Normalize(\n",
        "    mean=feature_extractor.image_mean, std=feature_extractor.image_std\n",
        ")\n",
        "\n",
        "_train_transforms = Compose(\n",
        "    [\n",
        "        RandomResizedCrop(feature_extractor.size),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "_val_transforms = Compose(\n",
        "    [\n",
        "        Resize(feature_extractor.size),\n",
        "        CenterCrop(feature_extractor.size),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "def train_transforms(examples):\n",
        "    examples[\"img_bytes\"] = [\n",
        "        _train_transforms(Image.open(io.BytesIO(image)).convert(\"RGB\")) for image in examples[\"img_bytes\"]\n",
        "    ]\n",
        "    return examples\n",
        "\n",
        "\n",
        "def val_transforms(examples):\n",
        "    examples[\"img_bytes\"] = [\n",
        "        _val_transforms(Image.open(io.BytesIO(image)).convert(\"RGB\")) for image in examples[\"img_bytes\"]\n",
        "    ]\n",
        "    return examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t8Uk1d9nqVnY"
      },
      "outputs": [],
      "source": [
        "train.set_transform(train_transforms)\n",
        "val.set_transform(val_transforms)\n",
        "test.set_transform(val_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyNN49N5qVna"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BqVXZ29uqVna"
      },
      "outputs": [],
      "source": [
        "from transformers import ViTForImageClassification\n",
        "from collections import defaultdict\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRHfIFXDqVnb",
        "outputId": "425d16b3-65a1-4d3f-9502-82febd2896ff"
      },
      "outputs": [],
      "source": [
        "model = ViTForImageClassification.from_pretrained('./pretrained_1',\n",
        "                                                  num_labels=7,\n",
        "                                                  id2label=id2label,\n",
        "                                                  label2id=label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtarvlMRqVnb",
        "outputId": "6bc2c1e5-f229-438a-bab2-dfedd0c8d2df"
      },
      "outputs": [],
      "source": [
        "metric_name = \"accuracy\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"test-fer-2013\",\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=10,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name,\n",
        "    logging_dir='logs',\n",
        "    remove_unused_columns=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e6tqCR8kqVnc"
      },
      "outputs": [],
      "source": [
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "n7AjFJ18qVnc"
      },
      "outputs": [],
      "source": [
        "def collate_fn(examples):\n",
        "    pixel_values = torch.stack([example[\"img_bytes\"] for example in examples])\n",
        "    labels = torch.tensor([example[\"labels\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gN2a1IvkqVnc"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train,\n",
        "    eval_dataset=val,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=feature_extractor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPvUJOKRtHxA",
        "outputId": "9fc80c64-d846-450f-c9bf-ddbe5b4f5adf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY7chf9WbYHK"
      },
      "source": [
        "## Predicting on custom image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Et9KxKh1QbRq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def process_image_from_array(image):\n",
        "  success, encoded_image = cv2.imencode('.png', image)\n",
        "  image = encoded_image.tobytes()\n",
        "\n",
        "  custom_set = dict()\n",
        "\n",
        "  f = image #.read()\n",
        "  _bytes = bytearray(f)\n",
        "\n",
        "  # image = Image.open(io.BytesIO(_bytes))\n",
        "  # imshow(image, \"gray\")\n",
        "\n",
        "  custom_set[\"img_bytes\"] = _train_transforms(Image.open(io.BytesIO(_bytes)).convert(\"RGB\"))\n",
        "  custom_set[\"labels\"] = 0\n",
        "\n",
        "  result = np.argmax(trainer.predict([custom_set], ignore_keys=[\"labels\"]).predictions)\n",
        "  return id2label[result]\n",
        "\n",
        "# \"angry\": 0,\n",
        "# \"disgust\": 1,\n",
        "# \"fear\": 2,\n",
        "# \"happy\": 3,\n",
        "# \"neutral\": 4,\n",
        "# \"sad\": 5,\n",
        "# \"surprise\": 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJQTZgDu0E63"
      },
      "source": [
        "# Realtime emotion detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kGAHXNzp0EZI"
      },
      "outputs": [],
      "source": [
        "from imutils.video import WebcamVideoStream\n",
        "from imutils.video import VideoStream\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import imutils\n",
        "import numpy as np\n",
        "import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript\n",
        "# from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "# from google.colab import files\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMTyGa620P7o",
        "outputId": "b8de0d51-e2c6-41d8-b69e-a6ebd14c7a36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading model...\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] loading model...\")\n",
        "prototxt = './preprocessing/deploy.prototxt'\n",
        "model = './preprocessing/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "net = cv2.dnn.readNetFromCaffe(prototxt, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LBM0RA5z0r0X"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'startY' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\AmirElkess\\Desktop\\local model testing\\process_ViT.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/AmirElkess/Desktop/local%20model%20testing/process_ViT.ipynb#ch0000025?line=27'>28</a>\u001b[0m         cv2\u001b[39m.\u001b[39mrectangle(frame, (startX\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, startY\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), (endX\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, endY\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/AmirElkess/Desktop/local%20model%20testing/process_ViT.ipynb#ch0000025?line=28'>29</a>\u001b[0m         \u001b[39m# cv2.putText(frame, text, (startX, y),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/AmirElkess/Desktop/local%20model%20testing/process_ViT.ipynb#ch0000025?line=29'>30</a>\u001b[0m         \u001b[39m#     cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/AmirElkess/Desktop/local%20model%20testing/process_ViT.ipynb#ch0000025?line=30'>31</a>\u001b[0m    \u001b[39m#if confidence >=0.9:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/AmirElkess/Desktop/local%20model%20testing/process_ViT.ipynb#ch0000025?line=31'>32</a>\u001b[0m         \u001b[39m#cv2.imwrite(\"frame%d.jpg\" % count, cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/AmirElkess/Desktop/local%20model%20testing/process_ViT.ipynb#ch0000025?line=32'>33</a>\u001b[0m         \u001b[39m#count += 1\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/AmirElkess/Desktop/local%20model%20testing/process_ViT.ipynb#ch0000025?line=34'>35</a>\u001b[0m cropped_frame \u001b[39m=\u001b[39m frame[startY:endY, startX:endX]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/AmirElkess/Desktop/local%20model%20testing/process_ViT.ipynb#ch0000025?line=35'>36</a>\u001b[0m cropped_frame \u001b[39m=\u001b[39m imutils\u001b[39m.\u001b[39mresize(cropped_frame, width\u001b[39m=\u001b[39m\u001b[39m48\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/AmirElkess/Desktop/local%20model%20testing/process_ViT.ipynb#ch0000025?line=36'>37</a>\u001b[0m cropped_frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(cropped_frame,cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'startY' is not defined"
          ]
        }
      ],
      "source": [
        "vs = WebcamVideoStream(src=0).start()\n",
        "# time.sleep(1)\n",
        "count = 0\n",
        "started = False\n",
        "frame_counter = 0\n",
        "while True:\n",
        "# grab the frame from the threaded video stream and resize it\n",
        "# to have a maximum width of 400 pixels\n",
        "    frame1 = vs.read()\n",
        "    frame = imutils.resize(frame1, width=400)\n",
        "    (h, w) = frame.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "    for i in range(0, detections.shape[2]):\n",
        "\n",
        "        # extract the confidence (i.e., probability) associated with the prediction\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "\n",
        "        # filter out weak detections by ensuring the `confidence` is\n",
        "        # greater than the minimum confidence threshold\n",
        "        if confidence > 0.5:\n",
        "            started = True\n",
        "            # compute the (x, y)-coordinates of the bounding box for the object\n",
        "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "            # draw the bounding box of the face along with the associated probability\n",
        "            # text = \"{:.2f}%\".format(confidence * 100)\n",
        "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "            cv2.rectangle(frame, (startX-1, startY-1), (endX+1, endY+1), (0, 0, 255), 1)\n",
        "            # cv2.putText(frame, text, (startX, y),\n",
        "            #     cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "       #if confidence >=0.9:\n",
        "            #cv2.imwrite(\"frame%d.jpg\" % count, cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY))\n",
        "            #count += 1\n",
        "\n",
        "    if started:\n",
        "        cropped_frame = frame[startY:endY, startX:endX]\n",
        "        cropped_frame = imutils.resize(cropped_frame, width=48)\n",
        "        cropped_frame = cv2.cvtColor(cropped_frame,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        prediction_text = process_image_from_array(cropped_frame)\n",
        "        \n",
        "        cv2.putText(frame, prediction_text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "        cv2.imshow(\"Frame\",frame)\n",
        "\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "    if key == ord(\"q\"):\n",
        "        break\n",
        "cv2.destroyAllWindows()\n",
        "vs.stop()\n",
        "vs.stream.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "process_ViT.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ac25d328fc9c119f02203596e2acace7f3bb63f31f4b85a1133c87a13bb1ade5"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0322e835b5f1408895c264d57b62931e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1441a112ee2a4b8c80b2efeabb5855a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2af4c8b59ba24ceb9dd1a935706ba57c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1441a112ee2a4b8c80b2efeabb5855a9",
            "placeholder": "​",
            "style": "IPY_MODEL_feca5d721e6e4872a4be81bdbf7c7f37",
            "value": "100%"
          }
        },
        "2d7c1b735e2341b2918b1261806e46b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38f6d6fdf10f48b393b36997cfeea627": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570471a4c14f4a2b842ae64a58fb34a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b686c8b7aa374fd18072ec20f4b9fa8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2af4c8b59ba24ceb9dd1a935706ba57c",
              "IPY_MODEL_d0e5b153fee24ba4b334d02463a5d0b4",
              "IPY_MODEL_e455b6c2e80c402eb2e9954944c0e634"
            ],
            "layout": "IPY_MODEL_570471a4c14f4a2b842ae64a58fb34a1"
          }
        },
        "d0e5b153fee24ba4b334d02463a5d0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f592a6fd63ca415ea5157c664fa811f5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d7c1b735e2341b2918b1261806e46b1",
            "value": 2
          }
        },
        "e455b6c2e80c402eb2e9954944c0e634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f6d6fdf10f48b393b36997cfeea627",
            "placeholder": "​",
            "style": "IPY_MODEL_0322e835b5f1408895c264d57b62931e",
            "value": " 2/2 [00:00&lt;00:00, 57.19it/s]"
          }
        },
        "f592a6fd63ca415ea5157c664fa811f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feca5d721e6e4872a4be81bdbf7c7f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
